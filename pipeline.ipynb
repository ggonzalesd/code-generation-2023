{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/poggers/dev/project/final/.env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from datapy import DataPy, PreProcessingTransform\n",
    "from embedding import EmbeddingBlock\n",
    "from model import MyTransformer, Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32768, 32768)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('codeparrot/codeparrot')\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "\n",
    "PAD_IDX = tokenizer.pad_token_id\n",
    "VOCAB_SIZE = tokenizer.vocab_size\n",
    "PAD_IDX, VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataPy(\n",
    "  csv_filename='./data/dataset.csv',\n",
    "  path='./data/',\n",
    "  transform=PreProcessingTransform(tokenizer)\n",
    ")\n",
    "\n",
    "dl = DataLoader(\n",
    "  dataset,\n",
    "  batch_size=3,\n",
    "  shuffle=True,\n",
    "  collate_fn=DataPy.create_collate_fn(True, PAD_IDX)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 328]),\n",
       " torch.int64,\n",
       " torch.Size([3]),\n",
       " torch.int64,\n",
       " torch.Size([3, 328]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch, lengths, padding_mask = next(iter(dl))\n",
    "X_batch.shape, X_batch.dtype, lengths.shape, lengths.dtype, padding_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = 256\n",
    "max_steps = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_block = EmbeddingBlock(VOCAB_SIZE+1, d_model, PAD_IDX, max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask_from_lengths(X, lengths):\n",
    "  batch_size, seq_length = X.shape\n",
    "  mask = torch.linspace(\n",
    "    0, seq_length-1, seq_length, dtype=torch.long\n",
    "  ).expand(batch_size, -1) < lengths.reshape(-1, 1)\n",
    "  return mask\n",
    "#create_mask_from_lengths(X_batch, lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, seq_length = X_batch.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class MyEncoderTransformer(nn.Module):\n",
    "  def __init__(self, d_model, nheads, dropout=0.1, dim_feedforward=2048, activation=F.gelu, device=None, dtype=None):\n",
    "    factory_kwargs = { 'device': device, 'dtype': dtype }\n",
    "    super(MyEncoderTransformer, self).__init__()\n",
    "    \n",
    "    self.self_attn = nn.MultiheadAttention(d_model, nheads, dropout, True, batch_first=True, **factory_kwargs)\n",
    "    self.dropout1 = nn.Dropout(dropout)\n",
    "    self.norm1 = nn.LayerNorm(d_model, **factory_kwargs)\n",
    "\n",
    "    self.linear1 = nn.Linear(d_model, dim_feedforward, **factory_kwargs)\n",
    "    self.dropout = nn.Dropout(dropout)\n",
    "    self.linear2 = nn.Linear(dim_feedforward, d_model, **factory_kwargs)\n",
    "    self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    self.norm2 = nn.LayerNorm(d_model, **factory_kwargs)\n",
    "\n",
    "    self.activation = activation\n",
    "  \n",
    "  def _sa_block(self, x, attn_mask, padding_mask) -> torch.Tensor:\n",
    "    x, _ = self.self_attn(x, x, x, attn_mask=attn_mask, key_padding_mask=padding_mask, need_weights=False)\n",
    "    return self.dropout1(x)\n",
    "\n",
    "  def _ff_block(self, x) -> torch.Tensor:\n",
    "    x = self.linear2(self.dropout(self.activation(self.linear1(x))))\n",
    "    return self.dropout2(x)\n",
    "\n",
    "  def forward(self, src, attn_mask=None, padding_mask=None):\n",
    "    x = src\n",
    "    x = self.norm1(x + self._sa_block(x, attn_mask, padding_mask))\n",
    "    x = self.norm2(x + self._ff_block(x))\n",
    "    return x\n",
    "\n",
    "class MyTransformer(nn.Module):\n",
    "  def __init__(self, d_model, nheads, num_layers, dropout=0.1, dim_feedforward=2048, activation=F.gelu, device=None, dtype=None):\n",
    "    factory_kwargs = { 'device': device, 'dtype': dtype }\n",
    "    super(MyTransformer, self).__init__()\n",
    "    self.layers = nn.ModuleList([\n",
    "      MyEncoderTransformer(d_model, nheads, dropout, dim_feedforward, activation, **factory_kwargs)\n",
    "      for _ in range(num_layers)\n",
    "    ])\n",
    "  \n",
    "  def forward(self, src, attn_mask=None, padding_mask=None):\n",
    "    for layer in self.layers:\n",
    "      src = layer(src, attn_mask, padding_mask)\n",
    "    return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.ModuleDict({\n",
    "  'backbone': MyTransformer(d_model, 4, 4),\n",
    "  'classification': Classification(d_model, VOCAB_SIZE+1)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = \"\"\"import numpy as np\"\"\"\n",
    "new_tokens = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 256])\n",
      "import numpy as np [_ [_ [_ [_ [_ [_ [_ [_ [_ [_\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  embedding_block.eval()\n",
    "  model.eval()\n",
    "\n",
    "  # [1] Pre-Processing\n",
    "  input_pp = dataset.transform(code).unsqueeze(0)\n",
    "\n",
    "  # [2] Embedding First (word embedding)\n",
    "  input_emb_f = embedding_block.first.word_embedding(input_pp)\n",
    "\n",
    "  # [3] Noise\n",
    "  noise = torch.randn(1, new_tokens, d_model)\n",
    "\n",
    "  # [4] concat origin with noise | get concated and origin mask\n",
    "  concated = torch.concat([input_emb_f, noise], dim=1)\n",
    "  origin_mask = torch.linspace(0, concated.shape[1]-1, concated.shape[1], dtype=torch.long) < input_pp.shape[1]\n",
    "  origin_mask = origin_mask.unsqueeze(0)\n",
    "\n",
    "  print(concated.shape)\n",
    "\n",
    "  # Tensor (i)\n",
    "  tensor = concated.clone()\n",
    "\n",
    "  for i in range(64):\n",
    "    step = i\n",
    "\n",
    "    # [5] Masked Replace\n",
    "    tensor[origin_mask] = concated[origin_mask]\n",
    "\n",
    "    # [6] Embedding Block (second)\n",
    "    tensor = embedding_block.second.forward(tensor, torch.LongTensor([63-step]), ~origin_mask)\n",
    "\n",
    "    # [7] Backbone Model\n",
    "    tensor = model.backbone(tensor)\n",
    "\n",
    "    # [8] Back\n",
    "  \n",
    "  # [9] Logits\n",
    "  logits = model.classification(tensor).argmax(dim=-1)\n",
    "  \n",
    "  # [10] Reverse Vocab\n",
    "  new_text = tokenizer.decode(logits[0].tolist()[-new_tokens:])\n",
    "\n",
    "# Show Results\n",
    "print(code + new_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
